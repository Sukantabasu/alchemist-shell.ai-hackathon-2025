{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4264a450fdba1b9",
   "metadata": {},
   "source": [
    "# Step #4\n",
    "\n",
    "## ML Predictions using the TabPFN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a46dc4e0eca8ce8",
   "metadata": {},
   "source": [
    "**Last update: August 14, 2025**\n",
    "\n",
    "AI Assistance: Claude.AI (Anthropic) is used for documentation, code restructuring, and performance optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ae76abb5836470",
   "metadata": {},
   "source": [
    "This program is free software: you can redistribute it and/or modify\n",
    "it under the terms of the GNU General Public License as published by\n",
    "the Free Software Foundation, either version 3 of the License, or\n",
    "(at your option) any later version.\n",
    "\n",
    "This program is distributed in the hope that it will be useful,\n",
    "but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "GNU General Public License for more details.\n",
    "\n",
    "You should have received a copy of the GNU General Public License\n",
    "along with this program.  If not, see <https://www.gnu.org/licenses/>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9e4a488bb10f9c",
   "metadata": {},
   "source": [
    "**Overall Strategy**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5a84e6db4cf824",
   "metadata": {},
   "source": [
    "Step 1: Preprocess and engineer new features. \n",
    "\n",
    "Step 2: Use AutoGluon to generate OOF predictions for each target separately.\n",
    "These predictions will be used as additional input features in steps 3 and 4.\n",
    "\n",
    "Step 3: Train the RealMLP model with processed input (step 1) + ten\n",
    "AutoGluon-OOFs (step 2). These additional features will capture the correlation\n",
    "among targets effectively.\n",
    "\n",
    "**Step 4: Similar to step 3 except use the TabPFN model.**\n",
    "\n",
    "Step 5: Combine predictions from RealMLP (step 3) and TabPFN (step 4)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5a5f96ec5481ed",
   "metadata": {},
   "source": [
    "**Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6adf423812e21d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "\n",
    "from scipy.stats import hmean\n",
    "from sklearn.metrics import mean_absolute_percentage_error as mape\n",
    "\n",
    "import tabpfn\n",
    "from tabpfn import TabPFNRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f429af9e85f80d",
   "metadata": {},
   "source": [
    "**Set Random Seeds**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f179e689a9eb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(7)\n",
    "np.random.seed(7)\n",
    "\n",
    "# Force numpy to use legacy RandomState instead of Generator\n",
    "np.random.set_state(np.random.RandomState(7).get_state())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5804506945182c70",
   "metadata": {},
   "source": [
    "**User Input**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de412ee916ac69b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n-repetitions\n",
    "nTrials = 250  \n",
    "\n",
    "# Number of folds in k-fold\n",
    "nFolds = 8  \n",
    "\n",
    "# Number of input features + 10 OOFs\n",
    "nFeatures = 65 + 10\n",
    "\n",
    "# Number of target variables\n",
    "nTargets = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d389817c76e06067",
   "metadata": {},
   "source": [
    "**Input & Output Directories**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92237de6813a6bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = '/data/Sukanta/Works_AIML/2025_SHELL_FuelProperty/'\n",
    "DATA_DIR = ROOT_DIR + 'DATA/'\n",
    "ExtractedDATA_DIR = ROOT_DIR + 'ExtractedDATA/'\n",
    "Tuning_DIR = ROOT_DIR + 'Models/TabPFN/'\n",
    "\n",
    "# Create directory if it doesn't exist\n",
    "os.makedirs(Tuning_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d303e0888e3e76",
   "metadata": {},
   "source": [
    "**Load Processed Training and Testing Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750c8c2e4259275e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_XyTrnVal_org = pd.read_csv(ExtractedDATA_DIR + 'train_processed.csv')\n",
    "nSamples_TrnVal = df_XyTrnVal_org.shape[0]\n",
    "\n",
    "df_XTst = pd.read_csv(ExtractedDATA_DIR + 'test_processed.csv')\n",
    "nSamples_Tst = df_XTst.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43921b4896377bd",
   "metadata": {},
   "source": [
    "**Load AutoGluon-generated OOF Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4fa34309ef9b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_XTrnVal_AG_OOF = pd.read_csv(ExtractedDATA_DIR + 'AutoGluon_21600_OOF.csv')\n",
    "df_XTst_AG_OOF = pd.read_csv(ExtractedDATA_DIR + 'AutoGluon_21600_Tst.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7739f8dfe368add",
   "metadata": {},
   "source": [
    "**Combine Dataframes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6e9c28fa2ecfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_XyTrnVal = pd.concat([df_XTrnVal_AG_OOF, df_XyTrnVal_org], axis=1)\n",
    "df_XTst = pd.concat([df_XTst_AG_OOF, df_XTst], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646d44e111b4aad9",
   "metadata": {},
   "source": [
    "**Initialize Storage for Results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1186049efffffc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_yTrnVal_OOF = {}\n",
    "dict_yTst_pred_allFold = {}\n",
    "dict_CV_scores = {}\n",
    "\n",
    "for trial in range(nTrials):\n",
    "    dict_yTrnVal_OOF[trial] = {}\n",
    "    dict_yTst_pred_allFold[trial] = {}\n",
    "    dict_CV_scores[trial] = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722ac5adbdc1f4f0",
   "metadata": {},
   "source": [
    "**Iterative Single-target Training using TabPFN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44683d015bafb5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "nSamples_per_fold = int(nSamples_TrnVal / nFolds)\n",
    "\n",
    "# n-repetitions of TabPFN models (resampling)\n",
    "for trial in range(nTrials):\n",
    "\n",
    "    print(f\"\\n=== TRIAL {trial + 1}/{nTrials} ===\")\n",
    "\n",
    "    # Shuffle training dataset & track original index\n",
    "    shuffle_indx = np.random.permutation(nSamples_TrnVal)\n",
    "    restore_indx = np.argsort(shuffle_indx)\n",
    "    df_XyTrnVal_shuffled = (\n",
    "        df_XyTrnVal.iloc[shuffle_indx].reset_index(drop=True))\n",
    "\n",
    "    # Extract input features\n",
    "    XTrnVal_shuffled = df_XyTrnVal_shuffled.iloc[:, 0:nFeatures].values\n",
    "\n",
    "    # Multioutput targets\n",
    "    for target in range(nTargets):\n",
    "\n",
    "        print(f\"\\n--- Target {target + 1}/{nTargets} ---\")\n",
    "\n",
    "        # Extract single target from possible nTargets\n",
    "        yTrnVal_shuffled = (\n",
    "            df_XyTrnVal_shuffled.iloc[:, nFeatures + target].values)\n",
    "\n",
    "        # Initialize zero vectors for OOF & test predictions\n",
    "        yTrnVal_shuffled_pred = np.zeros_like(yTrnVal_shuffled)\n",
    "        yTst_pred = np.zeros((nSamples_Tst, nFolds))\n",
    "\n",
    "        # K-folds\n",
    "        for Fold in range(nFolds):\n",
    "            # Create validation indices for this fold\n",
    "            val_start = Fold * nSamples_per_fold\n",
    "            val_end = min((Fold + 1) * nSamples_per_fold, nSamples_TrnVal)\n",
    "            val_indices = list(range(val_start, val_end))\n",
    "\n",
    "            # Create training indices (all except validation fold)\n",
    "            trn_indices = list(range(0, val_start)) + list(\n",
    "                range(val_end, nSamples_TrnVal))\n",
    "\n",
    "            # Split features and targets\n",
    "            XTrn_shuffled_fold = XTrnVal_shuffled[trn_indices]\n",
    "            XVal_shuffled_fold = XTrnVal_shuffled[val_indices]\n",
    "\n",
    "            yTrn_shuffled_fold = yTrnVal_shuffled[trn_indices]\n",
    "            yVal_shuffled_fold = yTrnVal_shuffled[val_indices]\n",
    "\n",
    "            print(\n",
    "                f\"  Fold {Fold + 1}/{nFolds}: \"\n",
    "                f\"Train={len(trn_indices)}, \"\n",
    "                f\"Val={len(val_indices)}\")\n",
    "\n",
    "            # Initialize TabPFN model\n",
    "            regressor = TabPFNRegressor()\n",
    "\n",
    "            # Fit (no tuning) using TabPFN model\n",
    "            regressor.fit(XTrn_shuffled_fold, yTrn_shuffled_fold)\n",
    "\n",
    "            # Make predictions on the holdout set\n",
    "            yVal_shuffled_fold_pred = regressor.predict(XVal_shuffled_fold)\n",
    "            yTrnVal_shuffled_pred[val_indices] = yVal_shuffled_fold_pred\n",
    "\n",
    "            # Make predictions on the test set\n",
    "            yTst_pred[:, Fold] = regressor.predict(df_XTst.iloc[:, 0:nFeatures].values)\n",
    "            print(f\"Test predictions generated for Fold {Fold + 1}\")\n",
    "\n",
    "        # Restore the order of the indices\n",
    "        yTrnVal_OOF = yTrnVal_shuffled_pred[restore_indx]\n",
    "\n",
    "        # Average yTst_pred across various folds (harmonic mean)\n",
    "        yTst_pred_allFold = (hmean(np.abs(yTst_pred), axis=1) *\n",
    "                    np.sign(np.mean(yTst_pred, axis=1)))\n",
    "\n",
    "        # Store predictions\n",
    "        dict_yTrnVal_OOF[trial][target] = yTrnVal_OOF.copy()\n",
    "        dict_yTst_pred_allFold[trial][target] = yTst_pred_allFold.copy()\n",
    "\n",
    "        # Compute CV score\n",
    "        dict_CV_scores[trial][target] = mape(yTrnVal_shuffled,\n",
    "                                        yTrnVal_shuffled_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeeba9099cb0af36",
   "metadata": {},
   "source": [
    "**Average Results Across Trials**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad64263557f519e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== AVERAGING ACROSS TRIALS ===\")\n",
    "\n",
    "dict_yTrnVal_avg_final = {}\n",
    "dict_yTst_avg_final = {}\n",
    "dict_CV_scores_avg = {}\n",
    "\n",
    "for target in range(nTargets):\n",
    "    # Average training OOF predictions across trials\n",
    "    trial_TrnVal = [dict_yTrnVal_OOF[trial][target] for trial in range(nTrials)]\n",
    "    dict_yTrnVal_avg_final[target] = (hmean(np.abs(trial_TrnVal), axis=0) *\n",
    "                              np.sign(np.mean(trial_TrnVal, axis=0)))\n",
    "\n",
    "    # Average test OOF predictions across trials (use hmean)\n",
    "    trial_Tst = [dict_yTst_pred_allFold[trial][target] for trial in range(nTrials)]\n",
    "    dict_yTst_avg_final[target] = (hmean(np.abs(trial_Tst), axis=0) *\n",
    "                           np.sign(np.mean(trial_Tst, axis=0)))\n",
    "\n",
    "    # CV scores of averaged predictions\n",
    "    yTrnVal = (df_XyTrnVal.iloc[:, nFeatures + target].values)\n",
    "    dict_CV_scores_avg[target] = mape(yTrnVal, dict_yTrnVal_avg_final[target])\n",
    "\n",
    "    print(f\"Target {target + 1}: Avg CV MAPE = {dict_CV_scores_avg[target]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea0c91ab2e4404f",
   "metadata": {},
   "source": [
    "**Save Results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== SAVING RESULTS ===\")\n",
    "\n",
    "df_submission = pd.DataFrame()\n",
    "df_submission['ID'] = range(1, nSamples_Tst + 1)\n",
    "\n",
    "for target in range(nTargets):\n",
    "    column_name = f'BlendProperty{target+1}'\n",
    "    df_submission[column_name] = dict_yTst_avg_final[target]\n",
    "\n",
    "df_submission.to_csv(ExtractedDATA_DIR + 'TabPFN_submission.csv', index=False)\n",
    "\n",
    "print(f\"TabPFN training completed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
