{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Copyright (C) 2025 Sukanta Basu\n",
    "\n",
    "This program is free software: you can redistribute it and/or modify\n",
    "it under the terms of the GNU General Public License as published by\n",
    "the Free Software Foundation, either version 3 of the License, or\n",
    "(at your option) any later version.\n",
    "\n",
    "This program is distributed in the hope that it will be useful,\n",
    "but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "GNU General Public License for more details.\n",
    "\n",
    "You should have received a copy of the GNU General Public License\n",
    "along with this program.  If not, see <https://www.gnu.org/licenses/>."
   ],
   "id": "1416a6ae4710a657"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "File: Step1_Preprocess.py\n",
    "==========================\n",
    "\n",
    ":Author: Sukanta Basu\n",
    ":Date: 2025-8-8\n",
    ":Description: preprocessing and feature engineering\n",
    "\n",
    "Overall strategy:\n",
    "Step 1: preprocessing and feature generation\n",
    "\n",
    "Step 2: Use AutoGluon to generate OOF predictions for each target separately.\n",
    "These predictions will be used as additional input features in steps 3 and 4.\n",
    "\n",
    "Step 3: Train the RealMLP model with processed input (step 1) + ten\n",
    "AutoGluon-OOFs (step 2). These additional features will capture the correlation\n",
    "among targets effectively.\n",
    "\n",
    "Step 4: Similar to step 3 except use the TabPFN model.\n",
    "\n",
    "Step 5: Combine predictions from RealMLP (step 3) and TabPFN (step 4)."
   ],
   "id": "2f436ceb8f384cb1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ============================================================\n",
    "# Imports\n",
    "# ============================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "random.seed(7)\n",
    "np.random.seed(7)"
   ],
   "id": "3dd86f72e702f7f1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Input & output directories\n",
    "# ============================================================\n",
    "\n",
    "ROOT_DIR = '/data/Sukanta/Works_AIML/2025_SHELL_FuelProperty/'\n",
    "DATA_DIR = ROOT_DIR + 'DATA/'\n",
    "ExtractedDATA_DIR = ROOT_DIR + 'ExtractedDATA/'\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Load training and testing data provided by the organizers\n",
    "# ============================================================\n",
    "\n",
    "df_XyTrnVal_org = pd.read_csv(DATA_DIR + 'train.csv')\n",
    "df_XTst_org = pd.read_csv(DATA_DIR + 'test.csv')\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Feature engineering\n",
    "# ============================================================\n",
    "\n",
    "# Create empty data frames\n",
    "df_XyTrnVal_mod = pd.DataFrame()\n",
    "df_XTst_mod = pd.DataFrame()\n",
    "\n",
    "# Add component fractions\n",
    "for comp in range(1, 6):\n",
    "    df_XyTrnVal_mod[f'Component{comp}_fraction'] = (\n",
    "        df_XyTrnVal_org)[f'Component{comp}_fraction']\n",
    "    df_XTst_mod[f'Component{comp}_fraction'] = (\n",
    "        df_XTst_org)[f'Component{comp}_fraction']\n",
    "\n",
    "# Create volume fraction-weighted input features\n",
    "for prop in range(1, 11):\n",
    "    for comp in range(1, 6):\n",
    "        fraction_col = f'Component{comp}_fraction'\n",
    "        property_col = f'Component{comp}_Property{prop}'\n",
    "        contribution_col = f'Component{comp}_Contribution_Property{prop}'\n",
    "        df_XyTrnVal_mod[contribution_col] = (df_XyTrnVal_org[fraction_col] *\n",
    "                                             df_XyTrnVal_org[property_col])\n",
    "\n",
    "        df_XTst_mod[contribution_col] = (df_XTst_org[fraction_col] *\n",
    "                                             df_XTst_org[property_col])\n",
    "\n",
    "# Create weighted-averaged input features\n",
    "for prop in range(1, 11):\n",
    "    df_XyTrnVal_mod[f'WeightedAvg_Property{prop}'] = (\n",
    "        sum(df_XyTrnVal_org[f'Component{comp}_fraction'] *\n",
    "            df_XyTrnVal_org[f'Component{comp}_Property{prop}']\n",
    "            for comp in range(1, 6)))\n",
    "    df_XTst_mod[f'WeightedAvg_Property{prop}'] = (\n",
    "        sum(df_XTst_org[f'Component{comp}_fraction'] *\n",
    "            df_XTst_org[f'Component{comp}_Property{prop}']\n",
    "            for comp in range(1, 6)))\n",
    "\n",
    "# Add targets\n",
    "for target in range(1, 11):\n",
    "    df_XyTrnVal_mod[f'BlendProperty{target}'] = df_XyTrnVal_org[f'BlendProperty{target}']\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Save processed data\n",
    "# ============================================================\n",
    "\n",
    "df_XyTrnVal_mod.to_csv(ExtractedDATA_DIR + 'train_processed.csv',index=False)\n",
    "df_XTst_mod.to_csv(ExtractedDATA_DIR + 'test_processed.csv',index=False)\n"
   ],
   "id": "initial_id"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
